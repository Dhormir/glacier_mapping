{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates training patches for the landcover transfer learning task. The idea is to take the patches that we already extract, and whose coordinates are contained in the patches metadata, and write associated numpy masks giving landcover labels. We assume the raw landcover rasters have already been downloaded using the `landcover.ipynb` notebook. The overall process has the form\n",
    "\n",
    "1. Build a VRT from all the landcover tiles\n",
    "2. Define patches whose locations will be used to extract masks\n",
    "\n",
    "  a. Ensure that it's in the same CRS as the VRT\n",
    "  \n",
    "  b. Keep all the tiles with any glacier present\n",
    "  \n",
    "  c. (optional) Filter some of the tiles that don't have glacier.\n",
    "  \n",
    "3. For each patch...\n",
    "\n",
    "  a. Windowed read the underlying VRT at that patch's location\n",
    "  \n",
    "  b. Ensure that the mask is multichannel, with one channel per landcover type\n",
    "  \n",
    "  c. Write that data as a mask\n",
    "  \n",
    "  d. Copy the input data to the same transfer data directory\n",
    "  \n",
    "4. Shuffle those into training, development, and test datasets.\n",
    "\n",
    "In principle, we could also create metadata files with paths to the training / development / test data, but this would be a bit inconsistent with how we train the main glacier model, and we want to reuse as much code as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing this more generally, let's test out the process on a single tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "landcover_dir = Path(\"/datadrive/glaciers/landcover\")\n",
    "patch_geojson = Path(\"/datadrive/glaciers/processed/patches/patches.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def vrt_from_dir(input_dir, output_path=\"./output.vrt\", **kwargs):\n",
    "    inputs = [f for f in input_dir.glob(\"*.tif*\")]\n",
    "    subprocess.call([\"gdalbuildvrt\", \"-o\", output_path] + inputs)\n",
    "\n",
    "vrt_from_dir(landcover_dir, landcover_dir / \"landcover.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_metadata = gpd.read_file(patch_geojson)\n",
    "patch_metadata = patch_metadata.to_crs(tile.meta[\"crs\"])\n",
    "positive_ix = patch_metadata.mask_mean_0 > 0\n",
    "patch_keep = patch_metadata[patch_metadata.mask_mean_0 > 0]\n",
    "patch_zero = patch_metadata[patch_metadata.mask_mean_0 == 0]\n",
    "\n",
    "n_sample = min(len(patch_zero), 1000 * len(patch_keep))\n",
    "patch_random = patch_zero.sample(n = n_sample)\n",
    "patch_keep = pd.concat([patch_keep, patch_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.windows import from_bounds\n",
    "from scipy import interpolate\n",
    "grid_one = np.linspace(0, 512, 512, endpoint=False)\n",
    "patch_grids = [grid_one, grid_one]\n",
    "\n",
    "landcover = rasterio.open(landcover_dir / \"landcover.vrt\")\n",
    "\n",
    "for i in range(200):\n",
    "    patch_ = list(patch_keep.geometry.iloc[i].bounds)\n",
    "    mask = landcover.read(window=from_bounds(*patch_, landcover.transform))\n",
    "    for channel in range(1):\n",
    "        mask_im = mask[channel]\n",
    "        nmax = np.nanmax(mask_im)\n",
    "        if not (np.isnan(nmax) or nmax == 0):\n",
    "            x = np.load(patch_keep.img_slice[i])[:, :, [4, 3, 1]]\n",
    "            nx = np.nanmax(x)\n",
    "            if not (np.isnan(nx) or nx == 0):\n",
    "                plt.imshow(x / nx)\n",
    "                plt.show()\n",
    "\n",
    "                mask_im = mask_im / mask_im.max()\n",
    "                mask_grids = [\n",
    "                    np.linspace(0, mask_im.shape[1], mask_im.shape[1], endpoint=False),\n",
    "                    np.linspace(0, mask_im.shape[0], mask_im.shape[0], endpoint=False)\n",
    "                ]\n",
    "\n",
    "                f_interp = interpolate.interp2d(*mask_grids, mask_im)\n",
    "                mask_im = f_interp(*patch_grids)\n",
    "\n",
    "                plt.imshow(mask_im)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glaciers",
   "language": "python",
   "name": "glaciers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
